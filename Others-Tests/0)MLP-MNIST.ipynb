{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 0) Multi-layer-Perceptron: MNIST example",
   "id": "62ea4201eb46d63c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Aim: show how to use a mlp in the case of MNIST problem classification",
   "id": "92269a4195339b0f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T17:26:33.525073Z",
     "start_time": "2024-09-26T17:26:28.361535Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('Others-Tests/train.csv').values\n",
    "test_data  = pd.read_csv('Others-Tests/test.csv').values "
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "print(train_data.shape) # (42000, 785)\n",
    "print(test_data.shape)  # (28000, 784)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T17:26:37.780177Z",
     "start_time": "2024-09-26T17:26:37.770179Z"
    }
   },
   "id": "2994748839c5ccca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are given the train and test data sets. In the train data set, there are 42,000 hand-written images of size 28x28. The first column of the CSV is going to be which digit the image represents(we call this ground truth and/or label), and the rest are 28x28=784 pixels with value ranged in [0, 255]. The test data set contains 28,000 entries and it does not have the ground truth column, because it is our job to figure out what the label actually is."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69cf15bab2e1828a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare the data with PyTorch",
   "id": "f68d487fb887533"
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T17:26:56.400901Z",
     "start_time": "2024-09-26T17:26:56.379902Z"
    }
   },
   "id": "cbfba9d79ff3be8a",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.data[ind][1:] / 255.0\n",
    "        y = self.data[ind][0]\n",
    "        return x, y\n",
    "    \n",
    "class TestDataset(TrainDataset):\n",
    " def __getitem__(self, ind):\n",
    "    x = self.data[ind] / 255.0\n",
    "    return x\n",
    " \n",
    "train_set = TrainDataset(train_data)\n",
    "test_set  = TestDataset(test_data)\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T17:31:04.576028Z",
     "start_time": "2024-09-26T17:31:04.563995Z"
    }
   },
   "id": "2a66966c80c601e8",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "raw",
   "source": [
    "we want to create the data loader. But to obtain this data loader, we need to create a dataset. The dataset makes direct contacts with our freshly read data and processes the data on-the-fly, while the data loader does the labor and loads the data when we need it. The data loader will ask for a batch of data from the data set each time. And the dataset will do the pre-processing for this batch only, not the entire data set. There’s a trade-off between pre-process all data beforehand, or process them when you actually need them.\n",
    "\n",
    "To customize our own dataset, we define the TrainDataset and TestDataset that inherit from the PyTorch’s Dataset. We separate the Train and Test dataset classes because their __getitem__ outputs are different. Alternatively, we could also save a flag in __init__ that indicates how many outputs are there for the corresponding class instance.\n",
    "\n",
    "We divided the pixel values by 255.0. This step does two things: 1. it converts the values to float; 2. it normalizes the data to the range of [0, 1]. Normalization is a good practice.\n",
    "\n",
    "We also shuffled our train data when building the data loader. This randomness helps train the model because otherwise we will be stuck at the same training pattern.\n",
    "\n",
    "Batch size. It depends on the capability of our GPU and our configuration for other hyperparameters. I like to use a batch size of 2 when debugging my model. Yes, unfortunately, we will need to debug the model sometimes if we want to craft our own wheels and it is not an easy task. During the actual training, I find values between 16 to 512 make sense."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67152f086d9b92fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MODEL",
   "id": "3efdf7258c59b1ea"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear = nn.Linear(28*28, 10)\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "model = MLP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T17:32:25.657369Z",
     "start_time": "2024-09-26T17:32:25.637371Z"
    }
   },
   "id": "24a191cbe962a913",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "raw",
   "source": [
    "In this model, we have 784 inputs and 10 output units. Because we have 784 input pixels and 10 output digit classes. In PyTorch, that’s represented as nn.Linear(input_size, output_size). Actually, we don’t have a hidden layer in the example above.\n",
    "\n",
    "We also defined an optimizer here. Optimizers help the model find the minimum.\n",
    "\n",
    "We are using the CrossEntropyLoss function as our criterion here. The criterion lets the model how well it performed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "702c4701ccdf4190"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TRAIN THE MODEL",
   "id": "67ad09f80c7f5a5"
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for batch_num, input_data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = input_data\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_num % 40 == 0:\n",
    "         print('\\tEpoch %d | Batch %d | Loss %6.2f' % (epoch, batch_num, loss.item()))\n",
    "         print('Epoch %d | Loss %6.2f' % (epoch, sum(losses)/len(losses)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T17:54:15.785303Z",
     "start_time": "2024-09-26T17:53:58.236669Z"
    }
   },
   "id": "896045f5722ffcb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 0 | Batch 0 | Loss   2.31\n",
      "Epoch 0 | Loss   2.31\n",
      "\tEpoch 0 | Batch 40 | Loss   1.12\n",
      "Epoch 0 | Loss   1.62\n",
      "\tEpoch 0 | Batch 80 | Loss   0.76\n",
      "Epoch 0 | Loss   1.27\n",
      "\tEpoch 1 | Batch 0 | Loss   0.77\n",
      "Epoch 1 | Loss   0.77\n",
      "\tEpoch 1 | Batch 40 | Loss   0.57\n",
      "Epoch 1 | Loss   0.69\n",
      "\tEpoch 1 | Batch 80 | Loss   0.54\n",
      "Epoch 1 | Loss   0.63\n",
      "\tEpoch 2 | Batch 0 | Loss   0.50\n",
      "Epoch 2 | Loss   0.50\n",
      "\tEpoch 2 | Batch 40 | Loss   0.47\n",
      "Epoch 2 | Loss   0.51\n",
      "\tEpoch 2 | Batch 80 | Loss   0.46\n",
      "Epoch 2 | Loss   0.50\n",
      "\tEpoch 3 | Batch 0 | Loss   0.48\n",
      "Epoch 3 | Loss   0.48\n",
      "\tEpoch 3 | Batch 40 | Loss   0.42\n",
      "Epoch 3 | Loss   0.44\n",
      "\tEpoch 3 | Batch 80 | Loss   0.45\n",
      "Epoch 3 | Loss   0.43\n",
      "\tEpoch 4 | Batch 0 | Loss   0.44\n",
      "Epoch 4 | Loss   0.44\n",
      "\tEpoch 4 | Batch 40 | Loss   0.44\n",
      "Epoch 4 | Loss   0.40\n",
      "\tEpoch 4 | Batch 80 | Loss   0.36\n",
      "Epoch 4 | Loss   0.39\n",
      "\tEpoch 5 | Batch 0 | Loss   0.39\n",
      "Epoch 5 | Loss   0.39\n",
      "\tEpoch 5 | Batch 40 | Loss   0.33\n",
      "Epoch 5 | Loss   0.37\n",
      "\tEpoch 5 | Batch 80 | Loss   0.36\n",
      "Epoch 5 | Loss   0.37\n",
      "\tEpoch 6 | Batch 0 | Loss   0.35\n",
      "Epoch 6 | Loss   0.35\n",
      "\tEpoch 6 | Batch 40 | Loss   0.39\n",
      "Epoch 6 | Loss   0.36\n",
      "\tEpoch 6 | Batch 80 | Loss   0.33\n",
      "Epoch 6 | Loss   0.35\n",
      "\tEpoch 7 | Batch 0 | Loss   0.37\n",
      "Epoch 7 | Loss   0.37\n",
      "\tEpoch 7 | Batch 40 | Loss   0.33\n",
      "Epoch 7 | Loss   0.34\n",
      "\tEpoch 7 | Batch 80 | Loss   0.33\n",
      "Epoch 7 | Loss   0.34\n",
      "\tEpoch 8 | Batch 0 | Loss   0.31\n",
      "Epoch 8 | Loss   0.31\n",
      "\tEpoch 8 | Batch 40 | Loss   0.33\n",
      "Epoch 8 | Loss   0.33\n",
      "\tEpoch 8 | Batch 80 | Loss   0.33\n",
      "Epoch 8 | Loss   0.33\n",
      "\tEpoch 9 | Batch 0 | Loss   0.32\n",
      "Epoch 9 | Loss   0.32\n",
      "\tEpoch 9 | Batch 40 | Loss   0.33\n",
      "Epoch 9 | Loss   0.31\n",
      "\tEpoch 9 | Batch 80 | Loss   0.31\n",
      "Epoch 9 | Loss   0.32\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "raw",
   "source": [
    "Epochs are just how many times we would like the model to see the entire train data set. During each epoch, we iterate through the data loader in mini-batches.\n",
    "\n",
    "We let the model take a small step in each batch. And to do so, we are clearing the previous data with optimizer.zero_grad() before the step, and then loss.backward() and optimizer.step().\n",
    "\n",
    "Notice for all variables we have variable = variable.to(device). This ensures all variables stay on the same computation machine, either the CPU or the GPU, not both. Because PyTorch does not support cross-machine computation yet."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50e83f23916c799"
  },
  {
   "cell_type": "raw",
   "source": [
    "Get the predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30e71d070ef148df"
  },
  {
   "cell_type": "code",
   "source": [
    "import csv\n",
    "model.eval()\n",
    "\n",
    "with open('mlp_submission.csv', 'w') as f:\n",
    "    fieldnames = ['ImageId', 'Label']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, lineterminator = '\\n')\n",
    "    writer.writeheader()\n",
    "    image_id = 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x in test_loader:\n",
    "            x = x.to(device).float()\n",
    "\n",
    "            output = model(x).argmax(dim=1)\n",
    "            for y in output:\n",
    "                writer.writerow({fieldnames[0]: image_id,fieldnames[1]: y.item()})\n",
    "                image_id += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T17:55:17.933141Z",
     "start_time": "2024-09-26T17:55:16.762209Z"
    }
   },
   "id": "7374b194a234e448",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "raw",
   "source": [
    "This is also called the inference step. It looks a lot like the training process, except we are not taking the backward steps now. Also, we can turn on the with torch.no_grad(), which frees up unnecessary spaces and speeds up the process."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11e92093bfaa6a5e"
  },
  {
   "cell_type": "raw",
   "source": [
    "An actual MLP"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d8e19e39d9196f"
  },
  {
   "cell_type": "raw",
   "source": [
    "In the model above we do not have a hidden layer. So here is an example of a model with 512 hidden units in one hidden layer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c39370b7dcfcf605"
  },
  {
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.mlp(x)\n",
    "        #Test branch\n",
    "        return out\n",
    "\n",
    "model = MLP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T17:56:02.924385Z",
     "start_time": "2024-09-26T17:56:02.903100Z"
    }
   },
   "id": "406fb775d7e4f957",
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "raw",
   "source": [
    "The model has an accuracy of 91.8%. Barely an improvement from a single-layer model. Inside MLP there are a lot of multiplications that map the input domain (784 pixels) to the output domain (10 classes). By adding a lot of layers inside the model, we are not fundamentally changing this underlying mapping. So our performance won’t improve by a lot. Actually, we introduced the risk of gradient vanishing and gradient explosion."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1d5b86be6773fee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
